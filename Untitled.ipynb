{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e92176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed4e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Open          High           Low  \\\n",
      "Date                                                                  \n",
      "2023-10-30 00:00:00+00:00  34531.742188  34843.933594  34110.972656   \n",
      "2023-10-31 00:00:00+00:00  34500.078125  34719.253906  34083.308594   \n",
      "2023-11-01 00:00:00+00:00  34657.273438  35527.929688  34170.691406   \n",
      "2023-11-02 00:00:00+00:00  35441.578125  35919.843750  34401.574219   \n",
      "2023-11-03 00:00:00+00:00  34942.472656  34942.472656  34133.441406   \n",
      "2023-11-04 00:00:00+00:00  34736.324219  35256.031250  34616.691406   \n",
      "2023-11-05 00:00:00+00:00  35090.011719  35340.339844  34594.242188   \n",
      "2023-11-06 00:00:00+00:00  35044.789062  35286.027344  34765.363281   \n",
      "2023-11-07 00:00:00+00:00  35047.792969  35892.417969  34545.816406   \n",
      "2023-11-08 00:00:00+00:00  35419.476562  35994.417969  35147.800781   \n",
      "2023-11-09 00:00:00+00:00  35633.632812  37926.257812  35592.101562   \n",
      "2023-11-10 00:00:00+00:00  36702.250000  37493.800781  36362.753906   \n",
      "2023-11-11 00:00:00+00:00  37310.070312  37407.093750  36773.667969   \n",
      "2023-11-12 00:00:00+00:00  37133.992188  37227.691406  36779.117188   \n",
      "2023-11-13 00:00:00+00:00  37070.304688  37405.117188  36399.605469   \n",
      "2023-11-14 00:00:00+00:00  36491.789062  36753.351562  34948.500000   \n",
      "\n",
      "                                  Close       Volume  Dividends  Stock Splits  \n",
      "Date                                                                           \n",
      "2023-10-30 00:00:00+00:00  34502.363281  17184860315        0.0           0.0  \n",
      "2023-10-31 00:00:00+00:00  34667.781250  15758270810        0.0           0.0  \n",
      "2023-11-01 00:00:00+00:00  35437.253906  22446272005        0.0           0.0  \n",
      "2023-11-02 00:00:00+00:00  34938.242188  20998158544        0.0           0.0  \n",
      "2023-11-03 00:00:00+00:00  34732.324219  17158456701        0.0           0.0  \n",
      "2023-11-04 00:00:00+00:00  35082.195312   9561294264        0.0           0.0  \n",
      "2023-11-05 00:00:00+00:00  35049.355469  12412743996        0.0           0.0  \n",
      "2023-11-06 00:00:00+00:00  35037.371094  12693436420        0.0           0.0  \n",
      "2023-11-07 00:00:00+00:00  35443.562500  18834737789        0.0           0.0  \n",
      "2023-11-08 00:00:00+00:00  35655.277344  17295394918        0.0           0.0  \n",
      "2023-11-09 00:00:00+00:00  36693.125000  37762672382        0.0           0.0  \n",
      "2023-11-10 00:00:00+00:00  37313.968750  22711265155        0.0           0.0  \n",
      "2023-11-11 00:00:00+00:00  37138.050781  13924272142        0.0           0.0  \n",
      "2023-11-12 00:00:00+00:00  37054.519531  11545715999        0.0           0.0  \n",
      "2023-11-13 00:00:00+00:00  36502.355469  19057712790        0.0           0.0  \n",
      "2023-11-14 00:00:00+00:00  35537.640625  23857403554        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "#Gathering Historical Data\n",
    "# Define the ticker symbol and time period\n",
    "\n",
    "tickerSymbol = 'BTC-USD'\n",
    "start_date = '2023-10-30'\n",
    "end_date = '2023-11-15'\n",
    "\n",
    "# Fetch the historical data\n",
    "tickerData = yf.Ticker(tickerSymbol)\n",
    "tickerDf = tickerData.history(period='1d', start=start_date, end=end_date)\n",
    "\n",
    "print(tickerDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cec2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open            0\n",
      "High            0\n",
      "Low             0\n",
      "Close           0\n",
      "Volume          0\n",
      "Dividends       0\n",
      "Stock Splits    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identifying Missing Data\n",
    "missing_data = tickerDf.isnull().sum()\n",
    "\n",
    "# Filling Missing Data (here we fill with the mean, but this is subjective)\n",
    "tickerDf.fillna(tickerDf.mean(), inplace=True)\n",
    "\n",
    "print(missing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875b1502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Open          High           Low  \\\n",
      "Date                                                                  \n",
      "2023-10-30 00:00:00+00:00  34531.742188  34843.933594  34110.972656   \n",
      "2023-10-31 00:00:00+00:00  34500.078125  34719.253906  34083.308594   \n",
      "2023-11-01 00:00:00+00:00  34657.273438  35527.929688  34170.691406   \n",
      "2023-11-02 00:00:00+00:00  35441.578125  35919.843750  34401.574219   \n",
      "2023-11-03 00:00:00+00:00  34942.472656  34942.472656  34133.441406   \n",
      "2023-11-04 00:00:00+00:00  34736.324219  35256.031250  34616.691406   \n",
      "2023-11-05 00:00:00+00:00  35090.011719  35340.339844  34594.242188   \n",
      "2023-11-06 00:00:00+00:00  35044.789062  35286.027344  34765.363281   \n",
      "2023-11-07 00:00:00+00:00  35047.792969  35892.417969  34545.816406   \n",
      "2023-11-08 00:00:00+00:00  35419.476562  35994.417969  35147.800781   \n",
      "2023-11-09 00:00:00+00:00  35633.632812  37926.257812  35592.101562   \n",
      "2023-11-10 00:00:00+00:00  36702.250000  37493.800781  36362.753906   \n",
      "2023-11-11 00:00:00+00:00  37310.070312  37407.093750  36773.667969   \n",
      "2023-11-12 00:00:00+00:00  37133.992188  37227.691406  36779.117188   \n",
      "2023-11-13 00:00:00+00:00  37070.304688  37405.117188  36399.605469   \n",
      "2023-11-14 00:00:00+00:00  36491.789062  36753.351562  34948.500000   \n",
      "\n",
      "                                  Close       Volume  \n",
      "Date                                                  \n",
      "2023-10-30 00:00:00+00:00  34502.363281  17184860315  \n",
      "2023-10-31 00:00:00+00:00  34667.781250  15758270810  \n",
      "2023-11-01 00:00:00+00:00  35437.253906  22446272005  \n",
      "2023-11-02 00:00:00+00:00  34938.242188  20998158544  \n",
      "2023-11-03 00:00:00+00:00  34732.324219  17158456701  \n",
      "2023-11-04 00:00:00+00:00  35082.195312   9561294264  \n",
      "2023-11-05 00:00:00+00:00  35049.355469  12412743996  \n",
      "2023-11-06 00:00:00+00:00  35037.371094  12693436420  \n",
      "2023-11-07 00:00:00+00:00  35443.562500  18834737789  \n",
      "2023-11-08 00:00:00+00:00  35655.277344  17295394918  \n",
      "2023-11-09 00:00:00+00:00  36693.125000  37762672382  \n",
      "2023-11-10 00:00:00+00:00  37313.968750  22711265155  \n",
      "2023-11-11 00:00:00+00:00  37138.050781  13924272142  \n",
      "2023-11-12 00:00:00+00:00  37054.519531  11545715999  \n",
      "2023-11-13 00:00:00+00:00  36502.355469  19057712790  \n",
      "2023-11-14 00:00:00+00:00  35537.640625  23857403554  \n"
     ]
    }
   ],
   "source": [
    "#Drop the columns we don't need'Dividends' and 'Stock Splits''\n",
    "tickerDf = tickerDf.drop(columns=['Dividends', 'Stock Splits'])\n",
    "print(tickerDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3b0040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2023-10-30 00:00:00+00:00    1.273224\n",
      "2023-10-31 00:00:00+00:00    1.093476\n",
      "2023-11-01 00:00:00+00:00    0.257348\n",
      "2023-11-02 00:00:00+00:00    0.799587\n",
      "2023-11-03 00:00:00+00:00    1.023342\n",
      "2023-11-04 00:00:00+00:00    0.643164\n",
      "2023-11-05 00:00:00+00:00    0.678848\n",
      "2023-11-06 00:00:00+00:00    0.691871\n",
      "2023-11-07 00:00:00+00:00    0.250493\n",
      "2023-11-08 00:00:00+00:00    0.020439\n",
      "2023-11-09 00:00:00+00:00    1.107312\n",
      "2023-11-10 00:00:00+00:00    1.781936\n",
      "2023-11-11 00:00:00+00:00    1.590780\n",
      "2023-11-12 00:00:00+00:00    1.500013\n",
      "2023-11-13 00:00:00+00:00    0.900017\n",
      "2023-11-14 00:00:00+00:00    0.148266\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#adding z-score to the data\n",
    "\n",
    "z_scores = np.abs(stats.zscore(tickerDf['Close']))\n",
    "tickerDf = tickerDf[(z_scores < 3)]  # Keeping only rows with z-score less than 3\n",
    "\n",
    "print(z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bab1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "\n",
    "# Indicator Calculation (e.g., moving average)\n",
    "tickerDf['MA_10'] = tickerDf['Close'].rolling(window=10).mean()  # 10 days moving average\n",
    "\n",
    "# Normalization (Standard Scaling as example)\n",
    "scaler = StandardScaler()\n",
    "tickerDf['Close_Scaled'] = scaler.fit_transform(tickerDf[['Close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984b9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis\n",
    "\n",
    "tickerDf['Return'] = tickerDf['Close'].pct_change()  # Daily returns\n",
    "tickerDf['Volatility'] = tickerDf['Return'].rolling(window=30).std() * np.sqrt(30)  # Monthly volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9308e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x must have 2 complete cycles requires 60 observations. x only has 16 observation(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\64724\\OneDrive\\Desktop\\PROJECT 4\\Group2_Project4\\Untitled.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/64724/OneDrive/Desktop/PROJECT%204/Group2_Project4/Untitled.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Time Series Decomposition Plots\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/64724/OneDrive/Desktop/PROJECT%204/Group2_Project4/Untitled.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m decomposition \u001b[39m=\u001b[39m seasonal_decompose(tickerDf[\u001b[39m'\u001b[39;49m\u001b[39mClose\u001b[39;49m\u001b[39m'\u001b[39;49m], model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39madditive\u001b[39;49m\u001b[39m'\u001b[39;49m, period\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/64724/OneDrive/Desktop/PROJECT%204/Group2_Project4/Untitled.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m decomposition\u001b[39m.\u001b[39mplot()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/64724/OneDrive/Desktop/PROJECT%204/Group2_Project4/Untitled.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\64724\\anaconda3\\envs\\dev\\lib\\site-packages\\statsmodels\\tsa\\seasonal.py:164\u001b[0m, in \u001b[0;36mseasonal_decompose\u001b[1;34m(x, model, filt, period, two_sided, extrapolate_trend)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    160\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must specify a period or x must be a pandas object with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39ma PeriodIndex or a DatetimeIndex with a freq not set to None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         )\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m pfreq:\n\u001b[1;32m--> 164\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx must have 2 complete cycles requires \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m2\u001b[39m\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39mpfreq\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobservations. x only has \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m observation(s)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m filt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m period \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# split weights at ends\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: x must have 2 complete cycles requires 60 observations. x only has 16 observation(s)"
     ]
    }
   ],
   "source": [
    "# Time Series Decomposition Plots\n",
    "decomposition = seasonal_decompose(tickerDf['Close'], model='additive', period=30)\n",
    "decomposition.plot()\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmaps\n",
    "sns.heatmap(tickerDf.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 411851.83028440387\n"
     ]
    }
   ],
   "source": [
    "# Predictor Identification\n",
    "# Note: This is more about forming hypotheses and identifying potential predictors based on domain knowledge and initial analysis.\n",
    "\n",
    "# Theory Testing - Example with Simple Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming we want to predict 'Close' using 'Volume' (as an example)\n",
    "X = tickerDf[['Volume']]\n",
    "y = tickerDf['Close']\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Creating a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d543407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X = tickerDf[['Open', 'Close']] \n",
    "\n",
    "# Temporal Split (e.g., using the first 80% of data for training and the rest for testing)\n",
    "split_point = int(len(tickerDf) * 0.8)\n",
    "X_train, X_test = X[:split_point], X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d69772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 1252193024.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1252197760.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1252164992.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1252165248.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1252142592.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1252130176.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1252118912.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1252091008.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1252052096.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1252069376.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1252049280.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1252021248.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1252010112.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1252015744.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1252007040.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1251973376.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1251970176.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1251922432.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251960448.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251891584.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1251868544.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251872128.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1251828608.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251821440.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1251808384.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251790336.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251722624.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1251736192.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1251701504.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251743360.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1251674752.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1251660160.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251595520.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251644800.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251603328.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251637504.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251528704.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251543424.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1251502208.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1251488896.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251404416.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251411840.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251449856.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251368704.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251329920.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251374464.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1251252608.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1251280896.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1251192448.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251186560.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1251132032.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251164160.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251106304.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251033728.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251082240.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1251047296.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1251050624.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250957568.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250927488.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250957184.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250909696.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250744192.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1250878848.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250754432.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250786176.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250731776.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1250665088.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1250652288.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1250668416.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250582912.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250452352.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250492544.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250593920.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250416256.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1250426880.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250424320.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250534400.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250351872.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250373632.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250122112.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1250160256.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1250090240.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1249947136.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1249984000.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1249991168.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1249860608.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249929344.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249855360.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1249756544.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1249756288.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249781632.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249594880.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1249510016.0000\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1249639552.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249519488.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249436544.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249465472.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249440256.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249341568.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1249380992.0000\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Neural Network MSE: 1333315292.3671188\n",
      "Neural Network Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Neural Network initialization\n",
    "\n",
    "# Initialize the Neural Network\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model_nn.add(Dropout(0.2))  # Regularization with Dropout\n",
    "model_nn.add(Dense(64, activation='tanh'))  # Different activation function\n",
    "model_nn.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))  # L2 regularization\n",
    "model_nn.add(Dense(1))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model_nn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model_nn.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "nn_predictions = model_nn.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "nn_mse = mean_squared_error(y_test, nn_predictions)\n",
    "print(\"Neural Network MSE:\", nn_mse)\n",
    "\n",
    "# For accuracy (example: considering a prediction within a certain percentage of the actual value as accurate)\n",
    "accuracy_threshold = 0.05  # 5%\n",
    "nn_accurate_predictions = np.abs(nn_predictions.flatten() - y_test) <= accuracy_threshold * y_test\n",
    "nn_accuracy = np.mean(nn_accurate_predictions)\n",
    "print(\"Neural Network Accuracy:\", nn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1faf4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1198666368.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1193380224.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1188086144.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1182784128.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1177474176.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1172156288.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1166830336.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1161496448.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1156154240.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1150803968.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1145445376.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1140078464.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1134702976.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1129318912.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1123926400.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1118524928.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1113114752.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1107695488.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1102267136.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1096829568.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1091382784.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1085926656.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1080460928.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1074985600.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1069500608.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1064005824.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1058501120.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1052986560.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1047461824.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1041926976.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1036382208.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1030827008.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1025261568.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1019685888.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1014099712.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1008503296.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1002896448.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 997279168.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 991651520.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 986013376.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 980364992.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 974706176.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 969036992.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 963357504.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 957667904.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 951968064.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 946258240.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 940538304.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 934808384.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 929068608.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 923319296.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 917560320.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 911791808.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 906013888.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 900226880.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 894430720.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 888625728.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 882812096.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 876989760.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 871159104.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 865320448.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 859473728.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 853619264.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 847757504.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 841888192.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 836011968.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 830128960.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 824239360.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 818343616.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 812441792.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 806534336.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 800621376.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 794703360.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 788780480.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 782853120.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 776921536.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 770986176.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 765047104.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 759105024.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 753160000.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 747212480.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 741262848.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 735311552.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 729358656.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 723404864.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 717450432.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 711495744.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 705541184.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 699587328.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 693634304.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 687682752.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 681732928.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 675785280.0000\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 669840448.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 663898560.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 657960320.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 652025920.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 646096064.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 640171072.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 634251328.0000\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "LSTM MSE: 664410690.9068463\n",
      "LSTM Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#LSTM initialization\n",
    "\n",
    "# Reshape input for LSTM [samples, time steps, features]\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(1, X_train.shape[1])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "#prediction\n",
    "lstm_predictions = model.predict(X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1])))\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
    "print(\"LSTM MSE:\", lstm_mse)\n",
    "\n",
    "# For accuracy\n",
    "lstm_accurate_predictions = np.abs(lstm_predictions.flatten() - y_test) <= accuracy_threshold * y_test\n",
    "lstm_accuracy = np.mean(lstm_accurate_predictions)\n",
    "print(\"LSTM Accuracy:\", lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9d38b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      3\u001b[0m model_lstm \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 4\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39madd(Bidirectional(LSTM(\u001b[38;5;241m50\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), input_shape\u001b[38;5;241m=\u001b[39m(sequence_length, \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)))\n\u001b[0;32m      5\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39madd(Bidirectional(LSTM(\u001b[38;5;241m30\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      6\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "sequence_length = 5\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Bidirectional(LSTM(50, activation='relu', return_sequences=True), input_shape=(sequence_length, X_train.shape[2])))\n",
    "model_lstm.add(Bidirectional(LSTM(30, activation='relu')))\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Reshape input data for LSTM\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], sequence_length, X_train.shape[1]))\n",
    "\n",
    "# Train the model\n",
    "model_lstm.fit(X_train_reshaped, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
    "print(\"LSTM MSE:\", lstm_mse)\n",
    "\n",
    "# For accuracy\n",
    "lstm_accurate_predictions = np.abs(lstm_predictions.flatten() - y_test) <= accuracy_threshold * y_test\n",
    "lstm_accuracy = np.mean(lstm_accurate_predictions)\n",
    "print(\"LSTM Accuracy:\", lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457ee35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4752a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
